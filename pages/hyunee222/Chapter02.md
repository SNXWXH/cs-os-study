# 데이터

## 0과 1로 숫자를 표현하는 방법

### 정보 단위

컴퓨터는 0과 1만 이해, 
0과 1을 나타내는 가장 작은 정보 단위 = 비트(bit)

비트 = 2^n
1바이트(1Byte) = 8비트(256개의 값)<br>
1킬로바이트(1KB) = 1,000바이트(1,000Byte)<br>
1메가바이트(1MB) = 1,000킬로바이트(1,000KB)<br>
1기가바이트(1GB) = 1,000메가바이트(1,000MB)<br>
1테라바이트(1TB) = 1,000기가바이트(1,000GB) 

### 이진법

0과 1만으로 모든 숫자를 표현하는 방법 = 이진법(binary)

숫자 10은 일반적으로 보면 10이지만,
이진수로는 10이 아닌 2이기 때문에 이런 혼동을 예방하기 위해<br>
이진수는 끝에 아래첨자₍₂₎를 붙혀주거나 앞에 0b를 붙여줌.

ex: 8= 1000₍₂₎or 0b1000

음수는 2의 보수, 이진수의 0과 1을 뒤집고 +1 해준 값

ex: 이진수 11을 음수로 표현 11>00>01= 이진수 01

### 십육진법

데이터 표현을 위해 이진법과 함께 십육진법을 사용 `(0~9,A~F)`

이진수와 마찬가지로 숫자 뒤 아래첨자₍₁₆₎ 혹은 앞에 0x를 붙여 구분함.

이진법과 같이 십육진법을 쓰는이유 = 이진법은 0과 1로만 표현하다보니 숫자가 길어지는 단점이 있음, 십육진법이 이진법과 변환하기 쉬움

## 0과 1로 문자를 표현하는 방법

### 문자 집합과 인코딩

컴퓨터가 인식과 표현이 가능한 문자 모음 = 문자 집합(Character set)

∴ 컴퓨터는 문자 집합에 속해있는 문자만 이해가능<br>
ex: 문자 집합이 {a,b,c,d}이면 e,f,g는 이해하지 못함

문자 집합에 속해있는 문자를 0과 1로 변환해야 컴퓨터가 이해하는데, 이 변환 과정을 문자 인코딩 (character encoding) ,

이렇게 문자 인코딩을 거쳐 0과 1로 이루어져 나오는 결과값이 문자 코드가 됨.

이 문자 코드를 사람이 이해할수 있는 문자로 변환하는 과정을 문자 디코딩 (character decoding) 이라함. 

### 아스키 코드

알파벳, 아라비아 숫자, 일부 특수문자를 포함한 초창기 문자 집합 = 아스키 코드

아스키 문자는 128개의 문자를 표현할수 있고, 8비트를 사용하지만<br>
오류 검출을 위해 사용되는 패리티 비트(Parity bit)가 1비트를 사용하기 때문에 실질적으로 7비트만 사용함.

### EUC-KR

알파벳은 이어쓰면 단어가 되지만, 한글은 음절 하나하나가 초성,중성,종성의 조합으로 이루어져 있음

아스키 문자는 한글과 아스키 문자 집합 외의 문자, 특수문자를 표현할수없어 이를 보완한 인코딩 방식 = EUC-KR 

인코딩엔 2가지 방식이 존재

완성형 인코딩 = 글자가 각자 고유 코드를 가짐<br>
조합형 인코딩 = 자음과 모음이 코드를 가지고 이를 조합

기존 알파벳은 1바이트를 사용, EUC-KR로 인한 한글은 2바이트 사용

### 유니코드와 UTF-8

모든 나라 언어의 문자 집합과 인코딩 방식이 통일된 표준 인코딩 방식

EUC-KR보다 훨씬 다양한 언어 표현이 가능해 현재 가장 많이 사용되고 있는 표준 문자 집합
